{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlLjzJ9l9DWE"
      },
      "source": [
        "# GameVision 1.0: Advanced Basketball Analytics\n",
        "\n",
        "**Core Objective:** Orchestrate an intelligent computer vision pipeline to detect players, track basketball trajectories, and automate scoring analytics with high precision.\n",
        "\n",
        "### Step 1: Initialize the Intelligence Layer\n",
        "\n",
        "We begin by installing the foundational libraries:\n",
        "- **Ultralytics YOLO11:** Our state-of-the-art detection engine.\n",
        "- **Supervision:** A high-performance visualization toolkit for rendering analytics overlays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok4xap7q8t3H",
        "outputId": "dc3dd5c1-b76f-4250-9b26-42e29551f585"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "✅ Setup Complete\n"
          ]
        }
      ],
      "source": [
        "%pip install -U ultralytics supervision lapx --quiet\n",
        "import ultralytics\n",
        "import supervision as sv\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "# from google.colab import drive, files (if using google colab)\n",
        "\n",
        "%pip install ipywidgets --quiet\n",
        "# from tqdm.notebook import tqdm (if using google colab)\n",
        "from tqdm import tqdm # (if using local Jupyter notebook)\n",
        "\n",
        "\n",
        "print(\"✅ Setup Complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vRPpB3F9hGU"
      },
      "source": [
        "### Step 2: Environment Configuration\n",
        "\n",
        "Configure the workspace by mounting external storage (if applicable) and defining the video processing pipeline's source and destination paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VFf_JQ59mDO",
        "outputId": "5f4061c2-b616-437d-a431-d3d2d92bdc8e"
      },
      "outputs": [],
      "source": [
        "# drive.mount('/content/drive') # (if using google colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2mj81tB-_Yx3"
      },
      "outputs": [],
      "source": [
        "# UPDATE THESE PATHS\n",
        "INPUT_VIDEO_PATH = \"Inputs/game02.mp4\"\n",
        "\n",
        "# Uncomment one of the below output paths to choose the desired video style with respect to the processing applied\n",
        "OUTPUT_VIDEO_PATH = \"videos/game02/game02_ai.mp4\"\n",
        "# OUTPUT_VIDEO_PATH = \"videos/game02/game02_ai_heatvision.mp4\"\n",
        "# OUTPUT_VIDEO_PATH = \"videos/game02/game02_ai_line.mp4\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmhR0iWcGPt4"
      },
      "source": [
        "### Step 3: The Unified Analytics Engine\n",
        "\n",
        "This is the heart of GameVision. It integrates multiple computer vision techniques to ensure robust performance across diverse video conditions:\n",
        "\n",
        "1. **Adaptive Lighting Enhancement:** Uses CLAHE (Contrast Limited Adaptive Histogram Equalization) to normalize varying court lighting conditions.\n",
        "2. **Automated Hoop Spatial Analysis:** Dynamically detects the rim using HSV-based color isolation and spatial clustering to set up logical \"scoring gates.\"\n",
        "3. **Kalman Filter Trajectory Prediction:** Stabilizes ball tracking by predicting future coordinates based on velocity and historical position, maintaining continuity during fast-paced motion or partial occlusions.\n",
        "4. **ROI (Region of Interest) Inference Boost:** Implements a multi-stage inference strategy, triggering high-sensitivity detection in critical zones around the rim to ensure no basket is missed.\n",
        "5. **Stateful Scoring Logic:** A directional-aware state machine that tracks the ball through upper and lower gates to filter out false positives and count validated scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv_standard_vision"
      },
      "source": [
        "#### Style A: Standard Analytic Vision\n",
        "\n",
        "This mode provides a clean, professional broadcast-style output. It features:\n",
        "- **Refined Annotations:** Rounded bounding boxes for players and the ball.\n",
        "- **Trajectory Trails:** A temporal visual history of ball movement for better focus on arc and flight path.\n",
        "- **Dynamic HUD:** Real-time score display with a semi-transparent background."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rT3PJo4PG_3J"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Auto hoop gates detected:\n",
            "UPPER: [[195, 0], [314, 0], [314, 87], [195, 87]]\n",
            "LOWER: [[195, 74], [314, 74], [314, 194], [195, 194]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Master Logic Render: 100%|██████████| 1767/1767 [1:17:03<00:00,  2.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Render Complete! AI Counted: 8.\n",
            "Debug upper hits: 260 lower hits: 166 scores: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# AUTO HOOP GATES + (KALMAN + REACQUIRE) + ROBUST SCORE\n",
        "# NumPy 1.25 + HOOP ROI BOOST\n",
        "# FULL SELF-CONTAINED BLOCK (includes annotators + lighting)\n",
        "# ============================================================\n",
        "\n",
        "# 0. Setup annotators (NO LABELS)\n",
        "person_ann = sv.RoundBoxAnnotator(thickness=2, color=sv.Color.RED)\n",
        "ball_ann   = sv.RoundBoxAnnotator(thickness=2, color=sv.Color.WHITE)\n",
        "trace_ann  = sv.TraceAnnotator(thickness=3, trace_length=50)\n",
        "\n",
        "# 1. Load Model\n",
        "model = YOLO(\"yolo11x-seg.pt\")\n",
        "\n",
        "# ----------------------------\n",
        "# Lighting fix\n",
        "# ----------------------------\n",
        "def apply_lighting_fix(frame):\n",
        "    lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "    l2 = clahe.apply(l)\n",
        "    enhanced = cv2.merge((l2, a, b))\n",
        "    return cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "# ----------------------------\n",
        "# Auto hoop gates from rim color\n",
        "# ----------------------------\n",
        "def auto_hoop_gates_from_video(video_path: str):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    ok, frame = cap.read()\n",
        "    cap.release()\n",
        "    if not ok or frame is None:\n",
        "        raise RuntimeError(\"Could not read first frame.\")\n",
        "\n",
        "    H, W = frame.shape[:2]\n",
        "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    lower_orange = np.array([5, 60, 60], dtype=np.uint8)\n",
        "    upper_orange = np.array([30, 255, 255], dtype=np.uint8)\n",
        "    mask = cv2.inRange(hsv, lower_orange, upper_orange)\n",
        "\n",
        "    top_h = int(H * 0.30)\n",
        "    mask[top_h:, :] = 0\n",
        "    mask[:top_h, :int(W * 0.35)] = 0\n",
        "\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_DILATE, kernel, iterations=2)\n",
        "\n",
        "    ys, xs = np.where(mask > 0)\n",
        "    if len(xs) < 80:\n",
        "        raise RuntimeError(\"Rim not detected. Widen orange HSV thresholds.\")\n",
        "\n",
        "    x1, x2 = int(xs.min()), int(xs.max())\n",
        "    y1, y2 = int(ys.min()), int(ys.max())\n",
        "\n",
        "    rim_cx = (x1 + x2) / 2.0\n",
        "    if abs(rim_cx - (W / 2.0)) > (W * 0.22):\n",
        "        raise RuntimeError(\"Detected orange region is not near hoop center. Adjust mask exclusions.\")\n",
        "\n",
        "    rim_w = max(1, x2 - x1)\n",
        "    pad_x = int(max(10, rim_w * 0.20))\n",
        "\n",
        "    ux1 = max(0, x1 - pad_x)\n",
        "    ux2 = min(W - 1, x2 + pad_x)\n",
        "\n",
        "    uy1 = max(0, y1 - 8)\n",
        "    uy2 = min(H - 1, y2 + 18)\n",
        "\n",
        "    ly1 = min(H - 1, y2 + 5)\n",
        "    ly2 = min(H - 1, y2 + 125)\n",
        "\n",
        "    upper_poly = np.array([[ux1, uy1], [ux2, uy1], [ux2, uy2], [ux1, uy2]], dtype=int)\n",
        "    lower_poly = np.array([[ux1, ly1], [ux2, ly1], [ux2, ly2], [ux1, ly2]], dtype=int)\n",
        "    return upper_poly, lower_poly\n",
        "\n",
        "video_info = sv.VideoInfo.from_video_path(INPUT_VIDEO_PATH)\n",
        "\n",
        "try:\n",
        "    HOOP_UPPER_POLYGON, HOOP_LOWER_POLYGON = auto_hoop_gates_from_video(INPUT_VIDEO_PATH)\n",
        "    print(\"✅ Auto hoop gates detected:\")\n",
        "    print(\"UPPER:\", HOOP_UPPER_POLYGON.tolist())\n",
        "    print(\"LOWER:\", HOOP_LOWER_POLYGON.tolist())\n",
        "except Exception as e:\n",
        "    print(\"⚠️ Auto hoop gates failed, using fallback. Error:\", str(e))\n",
        "    HOOP_UPPER_POLYGON = np.array([[140, 0], [330, 0], [330, 95], [140, 95]], dtype=int)\n",
        "    HOOP_LOWER_POLYGON = np.array([[150, 85], [320, 85], [320, 215], [150, 215]], dtype=int)\n",
        "\n",
        "upper_zone = sv.PolygonZone(polygon=HOOP_UPPER_POLYGON)\n",
        "lower_zone = sv.PolygonZone(polygon=HOOP_LOWER_POLYGON)\n",
        "\n",
        "# ----------------------------\n",
        "# Ball stabilizer (Kalman filter)\n",
        "# ----------------------------\n",
        "class BallTrack:\n",
        "    def __init__(self):\n",
        "        self.kf = cv2.KalmanFilter(4, 2)\n",
        "        self.kf.transitionMatrix = np.array(\n",
        "            [[1, 0, 1, 0],\n",
        "             [0, 1, 0, 1],\n",
        "             [0, 0, 1, 0],\n",
        "             [0, 0, 0, 1]], dtype=np.float32\n",
        "        )\n",
        "        self.kf.measurementMatrix = np.array(\n",
        "            [[1, 0, 0, 0],\n",
        "             [0, 1, 0, 0]], dtype=np.float32\n",
        "        )\n",
        "        self.kf.processNoiseCov = np.eye(4, dtype=np.float32) * 1e-2\n",
        "        self.kf.measurementNoiseCov = np.eye(2, dtype=np.float32) * 2.5e-1\n",
        "        self.kf.errorCovPost = np.eye(4, dtype=np.float32)\n",
        "\n",
        "        self.initialized = False\n",
        "        self.missed = 0\n",
        "        self.w = 24.0\n",
        "        self.h = 24.0\n",
        "\n",
        "    def init(self, cx, cy, w, h):\n",
        "        self.kf.statePost = np.array([[cx], [cy], [0.0], [0.0]], dtype=np.float32)\n",
        "        self.kf.statePre = self.kf.statePost.copy()\n",
        "        self.w = float(w)\n",
        "        self.h = float(h)\n",
        "        self.initialized = True\n",
        "        self.missed = 0\n",
        "\n",
        "    def predict(self):\n",
        "        if not self.initialized:\n",
        "            return None\n",
        "        pred = self.kf.predict()\n",
        "        return float(pred[0, 0]), float(pred[1, 0])\n",
        "\n",
        "    def update(self, cx, cy, w=None, h=None):\n",
        "        m = np.array([[cx], [cy]], dtype=np.float32)\n",
        "        self.kf.correct(m)\n",
        "        if w is not None and h is not None:\n",
        "            self.w = 0.85 * self.w + 0.15 * float(w)\n",
        "            self.h = 0.85 * self.h + 0.15 * float(h)\n",
        "        self.missed = 0\n",
        "\n",
        "    def mark_missed(self):\n",
        "        if self.initialized:\n",
        "            self.missed += 1\n",
        "\n",
        "    def bbox(self):\n",
        "        if not self.initialized:\n",
        "            return None\n",
        "        cx = float(self.kf.statePost[0, 0])\n",
        "        cy = float(self.kf.statePost[1, 0])\n",
        "        x1 = cx - self.w / 2.0\n",
        "        y1 = cy - self.h / 2.0\n",
        "        x2 = cx + self.w / 2.0\n",
        "        y2 = cy + self.h / 2.0\n",
        "        return np.array([x1, y1, x2, y2], dtype=np.float32)\n",
        "\n",
        "def det_centroid_wh(dets: sv.Detections):\n",
        "    xyxy = dets.xyxy\n",
        "    cx = (xyxy[:, 0] + xyxy[:, 2]) / 2.0\n",
        "    cy = (xyxy[:, 1] + xyxy[:, 3]) / 2.0\n",
        "    w = (xyxy[:, 2] - xyxy[:, 0])\n",
        "    h = (xyxy[:, 3] - xyxy[:, 1])\n",
        "    return cx, cy, w, h\n",
        "\n",
        "def pick_best_ball_near_prediction(dets_ball: sv.Detections, pred_xy, max_dist=140):\n",
        "    if dets_ball is None or len(dets_ball) == 0:\n",
        "        return None\n",
        "\n",
        "    if pred_xy is None:\n",
        "        idx = int(np.argmax(dets_ball.confidence)) if dets_ball.confidence is not None else 0\n",
        "        return dets_ball[[idx]]\n",
        "\n",
        "    px, py = pred_xy\n",
        "    cx, cy, _, _ = det_centroid_wh(dets_ball)\n",
        "    d = np.sqrt((cx - px) ** 2 + (cy - py) ** 2)\n",
        "    idx = int(np.argmin(d))\n",
        "\n",
        "    if float(d[idx]) <= max_dist:\n",
        "        return dets_ball[[idx]]\n",
        "\n",
        "    idx2 = int(np.argmax(dets_ball.confidence)) if dets_ball.confidence is not None else 0\n",
        "    return dets_ball[[idx2]]\n",
        "\n",
        "def clamp_xyxy(xyxy, W, H):\n",
        "    x1, y1, x2, y2 = map(float, xyxy.tolist())\n",
        "    x1 = max(0, min(W - 1, x1))\n",
        "    y1 = max(0, min(H - 1, y1))\n",
        "    x2 = max(0, min(W - 1, x2))\n",
        "    y2 = max(0, min(H - 1, y2))\n",
        "    return np.array([x1, y1, x2, y2], dtype=np.float32)\n",
        "\n",
        "def union_gate_roi(upper_poly, lower_poly, W, H, pad=20):\n",
        "    xs = np.concatenate([upper_poly[:, 0], lower_poly[:, 0]])\n",
        "    ys = np.concatenate([upper_poly[:, 1], lower_poly[:, 1]])\n",
        "    x1 = max(0, int(xs.min()) - pad)\n",
        "    y1 = max(0, int(ys.min()) - pad)\n",
        "    x2 = min(W - 1, int(xs.max()) + pad)\n",
        "    y2 = min(H - 1, int(ys.max()) + pad)\n",
        "    return x1, y1, x2, y2\n",
        "\n",
        "def offset_detections(dets: sv.Detections, dx: int, dy: int):\n",
        "    if dets is None or len(dets) == 0:\n",
        "        return dets\n",
        "    xyxy = dets.xyxy.copy()\n",
        "    xyxy[:, [0, 2]] += dx\n",
        "    xyxy[:, [1, 3]] += dy\n",
        "    return sv.Detections(\n",
        "        xyxy=xyxy,\n",
        "        confidence=dets.confidence.copy() if dets.confidence is not None else None,\n",
        "        class_id=dets.class_id.copy() if dets.class_id is not None else None,\n",
        "        tracker_id=dets.tracker_id.copy() if dets.tracker_id is not None else None,\n",
        "    )\n",
        "\n",
        "def concat_dets(a: sv.Detections, b: sv.Detections):\n",
        "    if a is None or len(a) == 0:\n",
        "        return b\n",
        "    if b is None or len(b) == 0:\n",
        "        return a\n",
        "    return sv.Detections(\n",
        "        xyxy=np.concatenate([a.xyxy, b.xyxy], axis=0),\n",
        "        confidence=np.concatenate([a.confidence, b.confidence], axis=0)\n",
        "        if a.confidence is not None and b.confidence is not None else None,\n",
        "        class_id=np.concatenate([a.class_id, b.class_id], axis=0)\n",
        "        if a.class_id is not None and b.class_id is not None else None,\n",
        "        tracker_id=None,\n",
        "    )\n",
        "\n",
        "# -----------------------\n",
        "# Robust scoring state\n",
        "# -----------------------\n",
        "score = 0\n",
        "COOLDOWN_FRAMES = 45\n",
        "MAX_TRANSIT_FRAMES = 26\n",
        "MIN_DOWN_PIXELS = 24\n",
        "MISS_RESET_FRAMES = 20\n",
        "\n",
        "cooldown = 0\n",
        "attempt = {\"phase\": \"idle\", \"start_frame\": None, \"start_cy\": None}\n",
        "\n",
        "ball_track = BallTrack()\n",
        "MAX_MISSED_FRAMES = 30\n",
        "\n",
        "dbg_upper_hits = 0\n",
        "dbg_lower_hits = 0\n",
        "dbg_scores = 0\n",
        "\n",
        "# -----------------------\n",
        "# Continuous person boxes + trail even when Ultralytics tracker ids disappear\n",
        "# (annotation-only lightweight tracker)\n",
        "# -----------------------\n",
        "PERSON_MAX_MISSED = 18\n",
        "PERSON_MATCH_IOU = 0.18\n",
        "\n",
        "def _iou_xyxy(a, b):\n",
        "    ax1, ay1, ax2, ay2 = map(float, a)\n",
        "    bx1, by1, bx2, by2 = map(float, b)\n",
        "    ix1 = max(ax1, bx1)\n",
        "    iy1 = max(ay1, by1)\n",
        "    ix2 = min(ax2, bx2)\n",
        "    iy2 = min(ay2, by2)\n",
        "    iw = max(0.0, ix2 - ix1)\n",
        "    ih = max(0.0, iy2 - iy1)\n",
        "    inter = iw * ih\n",
        "    area_a = max(0.0, (ax2 - ax1)) * max(0.0, (ay2 - ay1))\n",
        "    area_b = max(0.0, (bx2 - bx1)) * max(0.0, (by2 - by1))\n",
        "    denom = area_a + area_b - inter\n",
        "    return (inter / denom) if denom > 1e-6 else 0.0\n",
        "\n",
        "class _PersonAnnotTracker:\n",
        "    def __init__(self):\n",
        "        self.next_id = 1\n",
        "        self.tracks = {}  # id -> {\"xyxy\": np.array(4), \"missed\": int}\n",
        "\n",
        "    def update(self, person_xyxy: np.ndarray):\n",
        "        for tid in list(self.tracks.keys()):\n",
        "            self.tracks[tid][\"missed\"] += 1\n",
        "\n",
        "        if person_xyxy is None or len(person_xyxy) == 0:\n",
        "            for tid in list(self.tracks.keys()):\n",
        "                if self.tracks[tid][\"missed\"] > PERSON_MAX_MISSED:\n",
        "                    self.tracks.pop(tid, None)\n",
        "            return\n",
        "\n",
        "        used_det = set()\n",
        "        track_ids = list(self.tracks.keys())\n",
        "\n",
        "        for tid in track_ids:\n",
        "            best_j = -1\n",
        "            best_iou = 0.0\n",
        "            tbox = self.tracks[tid][\"xyxy\"]\n",
        "            for j in range(len(person_xyxy)):\n",
        "                if j in used_det:\n",
        "                    continue\n",
        "                iou = _iou_xyxy(tbox, person_xyxy[j])\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "                    best_j = j\n",
        "            if best_j >= 0 and best_iou >= PERSON_MATCH_IOU:\n",
        "                self.tracks[tid][\"xyxy\"] = person_xyxy[best_j].astype(np.float32)\n",
        "                self.tracks[tid][\"missed\"] = 0\n",
        "                used_det.add(best_j)\n",
        "\n",
        "        for j in range(len(person_xyxy)):\n",
        "            if j in used_det:\n",
        "                continue\n",
        "            tid = self.next_id\n",
        "            self.next_id += 1\n",
        "            self.tracks[tid] = {\"xyxy\": person_xyxy[j].astype(np.float32), \"missed\": 0}\n",
        "\n",
        "        for tid in list(self.tracks.keys()):\n",
        "            if self.tracks[tid][\"missed\"] > PERSON_MAX_MISSED:\n",
        "                self.tracks.pop(tid, None)\n",
        "\n",
        "    def as_detections(self):\n",
        "        if len(self.tracks) == 0:\n",
        "            return None\n",
        "        tids = sorted(self.tracks.keys())\n",
        "        xyxy = np.stack([self.tracks[tid][\"xyxy\"] for tid in tids], axis=0).astype(np.float32)\n",
        "        return sv.Detections(\n",
        "            xyxy=xyxy,\n",
        "            confidence=np.ones((len(tids),), dtype=np.float32),\n",
        "            class_id=np.zeros((len(tids),), dtype=np.int32),\n",
        "            tracker_id=np.array(tids, dtype=np.int32),\n",
        "        )\n",
        "\n",
        "person_annot_tracker = _PersonAnnotTracker()\n",
        "\n",
        "# 5. Processing Loop\n",
        "frames_generator = sv.get_video_frames_generator(source_path=INPUT_VIDEO_PATH)\n",
        "\n",
        "with sv.VideoSink(target_path=OUTPUT_VIDEO_PATH, video_info=video_info) as sink:\n",
        "    frame_idx = -1\n",
        "\n",
        "    for frame in tqdm(frames_generator, total=video_info.total_frames, desc=\"Master Logic Render\"):\n",
        "        frame_idx += 1\n",
        "\n",
        "        enhanced_frame = apply_lighting_fix(frame)\n",
        "        H, W = enhanced_frame.shape[:2]\n",
        "\n",
        "        results = model.track(\n",
        "            enhanced_frame,\n",
        "            persist=True,\n",
        "            verbose=False,\n",
        "            conf=0.03,\n",
        "            iou=0.4,\n",
        "            tracker=\"botsort.yaml\"\n",
        "        )[0]\n",
        "\n",
        "        detections = sv.Detections.from_ultralytics(results)\n",
        "        detections = detections[(detections.class_id == 0) | (detections.class_id == 32)]\n",
        "\n",
        "        # HOOP ROI BOOST\n",
        "        rx1, ry1, rx2, ry2 = union_gate_roi(HOOP_UPPER_POLYGON, HOOP_LOWER_POLYGON, W, H, pad=30)\n",
        "        roi = enhanced_frame[ry1:ry2, rx1:rx2]\n",
        "\n",
        "        roi_ball = None\n",
        "        if roi.size > 0:\n",
        "            roi_res = model.predict(roi, verbose=False, conf=0.01, iou=0.35)[0]\n",
        "            roi_det = sv.Detections.from_ultralytics(roi_res)\n",
        "            roi_det = roi_det[roi_det.class_id == 32]\n",
        "            roi_ball = offset_detections(roi_det, dx=rx1, dy=ry1)\n",
        "\n",
        "        full_ball = detections[detections.class_id == 32]\n",
        "        merged_ball = concat_dets(full_ball, roi_ball)\n",
        "\n",
        "        # Ball: predict -> match -> update\n",
        "        pred_xy = ball_track.predict()\n",
        "        chosen = pick_best_ball_near_prediction(merged_ball, pred_xy, max_dist=160)\n",
        "\n",
        "        if chosen is not None and len(chosen) > 0:\n",
        "            cx, cy, bw, bh = det_centroid_wh(chosen)\n",
        "            cx = float(cx[0]); cy = float(cy[0])\n",
        "            bw = float(bw[0]); bh = float(bh[0])\n",
        "\n",
        "            if not ball_track.initialized:\n",
        "                ball_track.init(cx, cy, bw, bh)\n",
        "            else:\n",
        "                ball_track.update(cx, cy, bw, bh)\n",
        "        else:\n",
        "            ball_track.mark_missed()\n",
        "\n",
        "        # Virtual ball from Kalman\n",
        "        ball_for_zone = None\n",
        "        ball_cy = None\n",
        "\n",
        "        if ball_track.initialized and ball_track.missed <= MAX_MISSED_FRAMES:\n",
        "            bb = ball_track.bbox()\n",
        "            if bb is not None:\n",
        "                ball_xyxy = clamp_xyxy(bb, W, H)\n",
        "                ball_cy = float((ball_xyxy[1] + ball_xyxy[3]) / 2.0)\n",
        "                ball_for_zone = sv.Detections(\n",
        "                    xyxy=np.array([ball_xyxy], dtype=np.float32),\n",
        "                    confidence=np.array([1.0], dtype=np.float32),\n",
        "                    class_id=np.array([32], dtype=np.int32),\n",
        "                )\n",
        "        else:\n",
        "            ball_track.initialized = False\n",
        "\n",
        "        ball_seen = ball_for_zone is not None\n",
        "        in_upper = upper_zone.trigger(detections=ball_for_zone).any() if ball_seen else False\n",
        "        in_lower = lower_zone.trigger(detections=ball_for_zone).any() if ball_seen else False\n",
        "\n",
        "        if in_upper:\n",
        "            dbg_upper_hits += 1\n",
        "        if in_lower:\n",
        "            dbg_lower_hits += 1\n",
        "\n",
        "        if cooldown > 0:\n",
        "            cooldown -= 1\n",
        "\n",
        "        # Attempt state machine\n",
        "        if attempt[\"phase\"] == \"idle\":\n",
        "            if ball_seen and in_upper and cooldown == 0:\n",
        "                attempt[\"phase\"] = \"saw_upper\"\n",
        "                attempt[\"start_frame\"] = frame_idx\n",
        "                attempt[\"start_cy\"] = ball_cy\n",
        "\n",
        "        elif attempt[\"phase\"] == \"saw_upper\":\n",
        "            if (frame_idx - attempt[\"start_frame\"]) > MAX_TRANSIT_FRAMES:\n",
        "                attempt[\"phase\"] = \"idle\"\n",
        "                attempt[\"start_frame\"] = None\n",
        "                attempt[\"start_cy\"] = None\n",
        "\n",
        "            elif ball_seen and in_lower and cooldown == 0:\n",
        "                down_pixels = ball_cy - float(attempt[\"start_cy\"])\n",
        "                if down_pixels >= MIN_DOWN_PIXELS:\n",
        "                    score += 1\n",
        "                    cooldown = COOLDOWN_FRAMES\n",
        "                    dbg_scores += 1\n",
        "\n",
        "                attempt[\"phase\"] = \"idle\"\n",
        "                attempt[\"start_frame\"] = None\n",
        "                attempt[\"start_cy\"] = None\n",
        "\n",
        "            elif (not ball_seen) and (frame_idx - attempt[\"start_frame\"]) > MISS_RESET_FRAMES:\n",
        "                attempt[\"phase\"] = \"idle\"\n",
        "                attempt[\"start_frame\"] = None\n",
        "                attempt[\"start_cy\"] = None\n",
        "\n",
        "        # Annotation\n",
        "        annotated_frame = frame.copy()\n",
        "\n",
        "        # Always draw persons, even if Ultralytics tracker ids disappear after scene shifts\n",
        "        p_xyxy = detections[detections.class_id == 0].xyxy if len(detections) > 0 else np.zeros((0, 4), dtype=np.float32)\n",
        "        if p_xyxy is None:\n",
        "            p_xyxy = np.zeros((0, 4), dtype=np.float32)\n",
        "\n",
        "        person_annot_tracker.update(p_xyxy)\n",
        "        p_tracked = person_annot_tracker.as_detections()\n",
        "\n",
        "        if p_tracked is not None and len(p_tracked) > 0:\n",
        "            annotated_frame = trace_ann.annotate(scene=annotated_frame, detections=p_tracked)\n",
        "            annotated_frame = person_ann.annotate(scene=annotated_frame, detections=p_tracked)\n",
        "\n",
        "        if ball_for_zone is not None:\n",
        "            annotated_frame = ball_ann.annotate(scene=annotated_frame, detections=ball_for_zone)\n",
        "\n",
        "        cv2.polylines(annotated_frame, [HOOP_UPPER_POLYGON], True, (0, 255, 255), 2)\n",
        "        cv2.polylines(annotated_frame, [HOOP_LOWER_POLYGON], True, (255, 255, 0), 2)\n",
        "\n",
        "        # Scoreboard\n",
        "        h, w, _ = annotated_frame.shape\n",
        "        hud_w, margin = 320, 40\n",
        "        overlay = annotated_frame.copy()\n",
        "        cv2.rectangle(overlay, (w - hud_w - margin, h - 120), (w - margin, h - 40), (15, 15, 15), -1)\n",
        "        cv2.rectangle(overlay, (w - hud_w - margin, h - 120), (w - hud_w - margin + 10, h - 40), (0, 255, 0), -1)\n",
        "        annotated_frame = cv2.addWeighted(overlay, 0.7, annotated_frame, 0.3, 0)\n",
        "\n",
        "        cv2.putText(annotated_frame, \"BASKETBALL PERFORMANCE\", (w - hud_w - margin + 25, h - 95),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, (160, 160, 160), 1, cv2.LINE_AA)\n",
        "        cv2.putText(annotated_frame, f\"PTS: {score}\", (w - hud_w - margin + 25, h - 55),\n",
        "                    cv2.FONT_HERSHEY_DUPLEX, 1.2, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "        sink.write_frame(frame=annotated_frame)\n",
        "\n",
        "print(f\"\\n✅ Render Complete! AI Counted: {score}.\")\n",
        "print(\"Debug upper hits:\", dbg_upper_hits, \"lower hits:\", dbg_lower_hits, \"scores:\", dbg_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv_heatvision"
      },
      "source": [
        "#### Style B: Predictive Heatvision\n",
        "\n",
        "A high-contrast thermal visualization designed for intensity and subject focus. Key features include:\n",
        "- **Thermal Background:** Desaturated and color-mapped environment using `COLORMAP_JET`.\n",
        "- **Subject Saliency:** Soft silhouettes with a glow-dilation effect triggered by player movement.\n",
        "- **Enhanced Contrast:** High SUBJECT_GAIN settings to make athletes and the ball stand out against the court background."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0i8J-rjS1KB5"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # AUTO HOOP GATES + ROCK-SOLID BALL (KALMAN + REACQUIRE) + ROBUST SCORE\n",
        "# # (NO tracker_id REQUIRED) + NumPy 1.25 FIX + HOOP ROI BOOST\n",
        "# # FULL SELF-CONTAINED BLOCK (includes annotators + lighting fix)\n",
        "# # ============================================================\n",
        "\n",
        "# # 0. Setup annotators (NO LABELS)\n",
        "# person_ann = sv.RoundBoxAnnotator(thickness=2, color=sv.Color.RED)\n",
        "# ball_ann   = sv.RoundBoxAnnotator(thickness=2, color=sv.Color.WHITE)\n",
        "# trace_ann  = sv.TraceAnnotator(thickness=3, trace_length=50)\n",
        "\n",
        "# # 1. Load Model\n",
        "# model = YOLO(\"yolo11x-seg.pt\")\n",
        "\n",
        "# # ----------------------------\n",
        "# # Lighting fix\n",
        "# # ----------------------------\n",
        "# def apply_lighting_fix(frame):\n",
        "#     lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
        "#     l, a, b = cv2.split(lab)\n",
        "#     clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "#     l2 = clahe.apply(l)\n",
        "#     enhanced = cv2.merge((l2, a, b))\n",
        "#     return cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "# # ----------------------------\n",
        "# # Auto hoop gates from rim color\n",
        "# # ----------------------------\n",
        "# def auto_hoop_gates_from_video(video_path: str):\n",
        "#     cap = cv2.VideoCapture(video_path)\n",
        "#     ok, frame = cap.read()\n",
        "#     cap.release()\n",
        "#     if not ok or frame is None:\n",
        "#         raise RuntimeError(\"Could not read first frame.\")\n",
        "\n",
        "#     H, W = frame.shape[:2]\n",
        "#     hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "#     lower_orange = np.array([5, 60, 60], dtype=np.uint8)\n",
        "#     upper_orange = np.array([30, 255, 255], dtype=np.uint8)\n",
        "#     mask = cv2.inRange(hsv, lower_orange, upper_orange)\n",
        "\n",
        "#     top_h = int(H * 0.30)\n",
        "#     mask[top_h:, :] = 0\n",
        "#     mask[:top_h, :int(W * 0.35)] = 0\n",
        "\n",
        "#     kernel = np.ones((3, 3), np.uint8)\n",
        "#     mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "#     mask = cv2.morphologyEx(mask, cv2.MORPH_DILATE, kernel, iterations=2)\n",
        "\n",
        "#     ys, xs = np.where(mask > 0)\n",
        "#     if len(xs) < 80:\n",
        "#         raise RuntimeError(\"Rim not detected. Widen orange HSV thresholds.\")\n",
        "\n",
        "#     x1, x2 = int(xs.min()), int(xs.max())\n",
        "#     y1, y2 = int(ys.min()), int(ys.max())\n",
        "\n",
        "#     rim_cx = (x1 + x2) / 2.0\n",
        "#     if abs(rim_cx - (W / 2.0)) > (W * 0.22):\n",
        "#         raise RuntimeError(\"Detected orange region is not near hoop center. Adjust mask exclusions.\")\n",
        "\n",
        "#     rim_w = max(1, x2 - x1)\n",
        "#     pad_x = int(max(10, rim_w * 0.20))\n",
        "\n",
        "#     ux1 = max(0, x1 - pad_x)\n",
        "#     ux2 = min(W - 1, x2 + pad_x)\n",
        "\n",
        "#     uy1 = max(0, y1 - 8)\n",
        "#     uy2 = min(H - 1, y2 + 18)\n",
        "\n",
        "#     ly1 = min(H - 1, y2 + 5)\n",
        "#     ly2 = min(H - 1, y2 + 125)\n",
        "\n",
        "#     upper_poly = np.array([[ux1, uy1], [ux2, uy1], [ux2, uy2], [ux1, uy2]], dtype=int)\n",
        "#     lower_poly = np.array([[ux1, ly1], [ux2, ly1], [ux2, ly2], [ux1, ly2]], dtype=int)\n",
        "#     return upper_poly, lower_poly\n",
        "\n",
        "# video_info = sv.VideoInfo.from_video_path(INPUT_VIDEO_PATH)\n",
        "\n",
        "# try:\n",
        "#     HOOP_UPPER_POLYGON, HOOP_LOWER_POLYGON = auto_hoop_gates_from_video(INPUT_VIDEO_PATH)\n",
        "#     print(\"✅ Auto hoop gates detected:\")\n",
        "#     print(\"UPPER:\", HOOP_UPPER_POLYGON.tolist())\n",
        "#     print(\"LOWER:\", HOOP_LOWER_POLYGON.tolist())\n",
        "# except Exception as e:\n",
        "#     print(\"⚠️ Auto hoop gates failed, using fallback. Error:\", str(e))\n",
        "#     HOOP_UPPER_POLYGON = np.array([[140, 0], [330, 0], [330, 95], [140, 95]], dtype=int)\n",
        "#     HOOP_LOWER_POLYGON = np.array([[150, 85], [320, 85], [320, 215], [150, 215]], dtype=int)\n",
        "\n",
        "# upper_zone = sv.PolygonZone(polygon=HOOP_UPPER_POLYGON)\n",
        "# lower_zone = sv.PolygonZone(polygon=HOOP_LOWER_POLYGON)\n",
        "\n",
        "# # ----------------------------\n",
        "# # Ball stabilizer (Kalman filter)\n",
        "# # ----------------------------\n",
        "# class BallTrack:\n",
        "#     def __init__(self):\n",
        "#         self.kf = cv2.KalmanFilter(4, 2)\n",
        "#         self.kf.transitionMatrix = np.array(\n",
        "#             [[1, 0, 1, 0],\n",
        "#              [0, 1, 0, 1],\n",
        "#              [0, 0, 1, 0],\n",
        "#              [0, 0, 0, 1]], dtype=np.float32\n",
        "#         )\n",
        "#         self.kf.measurementMatrix = np.array(\n",
        "#             [[1, 0, 0, 0],\n",
        "#              [0, 1, 0, 0]], dtype=np.float32\n",
        "#         )\n",
        "#         self.kf.processNoiseCov = np.eye(4, dtype=np.float32) * 1e-2\n",
        "#         self.kf.measurementNoiseCov = np.eye(2, dtype=np.float32) * 2.5e-1\n",
        "#         self.kf.errorCovPost = np.eye(4, dtype=np.float32)\n",
        "\n",
        "#         self.initialized = False\n",
        "#         self.missed = 0\n",
        "#         self.w = 24.0\n",
        "#         self.h = 24.0\n",
        "\n",
        "#     def init(self, cx, cy, w, h):\n",
        "#         self.kf.statePost = np.array([[cx], [cy], [0.0], [0.0]], dtype=np.float32)\n",
        "#         self.kf.statePre = self.kf.statePost.copy()\n",
        "#         self.w = float(w)\n",
        "#         self.h = float(h)\n",
        "#         self.initialized = True\n",
        "#         self.missed = 0\n",
        "\n",
        "#     def predict(self):\n",
        "#         if not self.initialized:\n",
        "#             return None\n",
        "#         pred = self.kf.predict()\n",
        "#         return float(pred[0, 0]), float(pred[1, 0])\n",
        "\n",
        "#     def update(self, cx, cy, w=None, h=None):\n",
        "#         m = np.array([[cx], [cy]], dtype=np.float32)\n",
        "#         self.kf.correct(m)\n",
        "#         if w is not None and h is not None:\n",
        "#             self.w = 0.85 * self.w + 0.15 * float(w)\n",
        "#             self.h = 0.85 * self.h + 0.15 * float(h)\n",
        "#         self.missed = 0\n",
        "\n",
        "#     def mark_missed(self):\n",
        "#         if self.initialized:\n",
        "#             self.missed += 1\n",
        "\n",
        "#     def bbox(self):\n",
        "#         if not self.initialized:\n",
        "#             return None\n",
        "#         cx = float(self.kf.statePost[0, 0])\n",
        "#         cy = float(self.kf.statePost[1, 0])\n",
        "#         x1 = cx - self.w / 2.0\n",
        "#         y1 = cy - self.h / 2.0\n",
        "#         x2 = cx + self.w / 2.0\n",
        "#         y2 = cy + self.h / 2.0\n",
        "#         return np.array([x1, y1, x2, y2], dtype=np.float32)\n",
        "\n",
        "# def det_centroid_wh(dets: sv.Detections):\n",
        "#     xyxy = dets.xyxy\n",
        "#     cx = (xyxy[:, 0] + xyxy[:, 2]) / 2.0\n",
        "#     cy = (xyxy[:, 1] + xyxy[:, 3]) / 2.0\n",
        "#     w = (xyxy[:, 2] - xyxy[:, 0])\n",
        "#     h = (xyxy[:, 3] - xyxy[:, 1])\n",
        "#     return cx, cy, w, h\n",
        "\n",
        "# def pick_best_ball_near_prediction(dets_ball: sv.Detections, pred_xy, max_dist=140):\n",
        "#     if dets_ball is None or len(dets_ball) == 0:\n",
        "#         return None\n",
        "\n",
        "#     if pred_xy is None:\n",
        "#         idx = int(np.argmax(dets_ball.confidence)) if dets_ball.confidence is not None else 0\n",
        "#         return dets_ball[[idx]]\n",
        "\n",
        "#     px, py = pred_xy\n",
        "#     cx, cy, _, _ = det_centroid_wh(dets_ball)\n",
        "#     d = np.sqrt((cx - px) ** 2 + (cy - py) ** 2)\n",
        "#     idx = int(np.argmin(d))\n",
        "\n",
        "#     if float(d[idx]) <= max_dist:\n",
        "#         return dets_ball[[idx]]\n",
        "\n",
        "#     idx2 = int(np.argmax(dets_ball.confidence)) if dets_ball.confidence is not None else 0\n",
        "#     return dets_ball[[idx2]]\n",
        "\n",
        "# def clamp_xyxy(xyxy, W, H):\n",
        "#     x1, y1, x2, y2 = map(float, xyxy.tolist())\n",
        "#     x1 = max(0, min(W - 1, x1))\n",
        "#     y1 = max(0, min(H - 1, y1))\n",
        "#     x2 = max(0, min(W - 1, x2))\n",
        "#     y2 = max(0, min(H - 1, y2))\n",
        "#     return np.array([x1, y1, x2, y2], dtype=np.float32)\n",
        "\n",
        "# def union_gate_roi(upper_poly, lower_poly, W, H, pad=20):\n",
        "#     xs = np.concatenate([upper_poly[:, 0], lower_poly[:, 0]])\n",
        "#     ys = np.concatenate([upper_poly[:, 1], lower_poly[:, 1]])\n",
        "#     x1 = max(0, int(xs.min()) - pad)\n",
        "#     y1 = max(0, int(ys.min()) - pad)\n",
        "#     x2 = min(W - 1, int(xs.max()) + pad)\n",
        "#     y2 = min(H - 1, int(ys.max()) + pad)\n",
        "#     return x1, y1, x2, y2\n",
        "\n",
        "# def offset_detections(dets: sv.Detections, dx: int, dy: int):\n",
        "#     if dets is None or len(dets) == 0:\n",
        "#         return dets\n",
        "#     xyxy = dets.xyxy.copy()\n",
        "#     xyxy[:, [0, 2]] += dx\n",
        "#     xyxy[:, [1, 3]] += dy\n",
        "#     return sv.Detections(\n",
        "#         xyxy=xyxy,\n",
        "#         confidence=dets.confidence.copy() if dets.confidence is not None else None,\n",
        "#         class_id=dets.class_id.copy() if dets.class_id is not None else None,\n",
        "#         tracker_id=dets.tracker_id.copy() if dets.tracker_id is not None else None,\n",
        "#     )\n",
        "\n",
        "# def concat_dets(a: sv.Detections, b: sv.Detections):\n",
        "#     if a is None or len(a) == 0:\n",
        "#         return b\n",
        "#     if b is None or len(b) == 0:\n",
        "#         return a\n",
        "#     return sv.Detections(\n",
        "#         xyxy=np.concatenate([a.xyxy, b.xyxy], axis=0),\n",
        "#         confidence=np.concatenate([a.confidence, b.confidence], axis=0)\n",
        "#         if a.confidence is not None and b.confidence is not None else None,\n",
        "#         class_id=np.concatenate([a.class_id, b.class_id], axis=0)\n",
        "#         if a.class_id is not None and b.class_id is not None else None,\n",
        "#         tracker_id=None,\n",
        "#     )\n",
        "\n",
        "# # -----------------------\n",
        "# # Robust scoring state\n",
        "# # -----------------------\n",
        "# score = 0\n",
        "# COOLDOWN_FRAMES = 45\n",
        "# MAX_TRANSIT_FRAMES = 26\n",
        "# MIN_DOWN_PIXELS = 24\n",
        "# MISS_RESET_FRAMES = 20\n",
        "\n",
        "# cooldown = 0\n",
        "# attempt = {\"phase\": \"idle\", \"start_frame\": None, \"start_cy\": None}\n",
        "\n",
        "# ball_track = BallTrack()\n",
        "# MAX_MISSED_FRAMES = 30\n",
        "\n",
        "# dbg_upper_hits = 0\n",
        "# dbg_lower_hits = 0\n",
        "# dbg_scores = 0\n",
        "\n",
        "# # -----------------------\n",
        "# # Continuous person boxes + trail even when Ultralytics tracker ids disappear\n",
        "# # (annotation-only lightweight tracker)\n",
        "# # -----------------------\n",
        "# PERSON_MAX_MISSED = 18\n",
        "# PERSON_MATCH_IOU = 0.18\n",
        "\n",
        "# def _iou_xyxy(a, b):\n",
        "#     ax1, ay1, ax2, ay2 = map(float, a)\n",
        "#     bx1, by1, bx2, by2 = map(float, b)\n",
        "#     ix1 = max(ax1, bx1)\n",
        "#     iy1 = max(ay1, by1)\n",
        "#     ix2 = min(ax2, bx2)\n",
        "#     iy2 = min(ay2, by2)\n",
        "#     iw = max(0.0, ix2 - ix1)\n",
        "#     ih = max(0.0, iy2 - iy1)\n",
        "#     inter = iw * ih\n",
        "#     area_a = max(0.0, (ax2 - ax1)) * max(0.0, (ay2 - ay1))\n",
        "#     area_b = max(0.0, (bx2 - bx1)) * max(0.0, (by2 - by1))\n",
        "#     denom = area_a + area_b - inter\n",
        "#     return (inter / denom) if denom > 1e-6 else 0.0\n",
        "\n",
        "# class _PersonAnnotTracker:\n",
        "#     def __init__(self):\n",
        "#         self.next_id = 1\n",
        "#         self.tracks = {}  # id -> {\"xyxy\": np.array(4), \"missed\": int}\n",
        "\n",
        "#     def update(self, person_xyxy: np.ndarray):\n",
        "#         for tid in list(self.tracks.keys()):\n",
        "#             self.tracks[tid][\"missed\"] += 1\n",
        "\n",
        "#         if person_xyxy is None or len(person_xyxy) == 0:\n",
        "#             for tid in list(self.tracks.keys()):\n",
        "#                 if self.tracks[tid][\"missed\"] > PERSON_MAX_MISSED:\n",
        "#                     self.tracks.pop(tid, None)\n",
        "#             return\n",
        "\n",
        "#         used_det = set()\n",
        "#         track_ids = list(self.tracks.keys())\n",
        "\n",
        "#         for tid in track_ids:\n",
        "#             best_j = -1\n",
        "#             best_iou = 0.0\n",
        "#             tbox = self.tracks[tid][\"xyxy\"]\n",
        "#             for j in range(len(person_xyxy)):\n",
        "#                 if j in used_det:\n",
        "#                     continue\n",
        "#                 iou = _iou_xyxy(tbox, person_xyxy[j])\n",
        "#                 if iou > best_iou:\n",
        "#                     best_iou = iou\n",
        "#                     best_j = j\n",
        "#             if best_j >= 0 and best_iou >= PERSON_MATCH_IOU:\n",
        "#                 self.tracks[tid][\"xyxy\"] = person_xyxy[best_j].astype(np.float32)\n",
        "#                 self.tracks[tid][\"missed\"] = 0\n",
        "#                 used_det.add(best_j)\n",
        "\n",
        "#         for j in range(len(person_xyxy)):\n",
        "#             if j in used_det:\n",
        "#                 continue\n",
        "#             tid = self.next_id\n",
        "#             self.next_id += 1\n",
        "#             self.tracks[tid] = {\"xyxy\": person_xyxy[j].astype(np.float32), \"missed\": 0}\n",
        "\n",
        "#         for tid in list(self.tracks.keys()):\n",
        "#             if self.tracks[tid][\"missed\"] > PERSON_MAX_MISSED:\n",
        "#                 self.tracks.pop(tid, None)\n",
        "\n",
        "#     def as_detections(self):\n",
        "#         if len(self.tracks) == 0:\n",
        "#             return None\n",
        "#         tids = sorted(self.tracks.keys())\n",
        "#         xyxy = np.stack([self.tracks[tid][\"xyxy\"] for tid in tids], axis=0).astype(np.float32)\n",
        "#         return sv.Detections(\n",
        "#             xyxy=xyxy,\n",
        "#             confidence=np.ones((len(tids),), dtype=np.float32),\n",
        "#             class_id=np.zeros((len(tids),), dtype=np.int32),\n",
        "#             tracker_id=np.array(tids, dtype=np.int32),\n",
        "#         )\n",
        "\n",
        "# person_annot_tracker = _PersonAnnotTracker()\n",
        "\n",
        "# # -----------------------\n",
        "# # Heatvision settings (match reference style)\n",
        "# # -----------------------\n",
        "# HEATVISION_COLORMAP = cv2.COLORMAP_JET\n",
        "# HEAT_BLUR_SIGMA = 2.2\n",
        "\n",
        "# BG_DARKEN = 0.22\n",
        "# SUBJECT_GAIN = 1.15\n",
        "# SUBJECT_GAMMA = 0.75\n",
        "# GLOW_DILATE = 10\n",
        "# GLOW_ALPHA = 0.55\n",
        "\n",
        "# def _soft_silhouette_from_xyxy(xyxy: np.ndarray, H: int, W: int, feather: int = 10):\n",
        "#     mask = np.zeros((H, W), dtype=np.uint8)\n",
        "#     if xyxy is None or len(xyxy) == 0:\n",
        "#         return mask\n",
        "#     for b in xyxy:\n",
        "#         x1, y1, x2, y2 = [int(round(v)) for v in b.tolist()]\n",
        "#         x1 = max(0, min(W - 1, x1))\n",
        "#         y1 = max(0, min(H - 1, y1))\n",
        "#         x2 = max(0, min(W - 1, x2))\n",
        "#         y2 = max(0, min(H - 1, y2))\n",
        "#         if x2 <= x1 or y2 <= y1:\n",
        "#             continue\n",
        "#         cv2.rectangle(mask, (x1, y1), (x2, y2), 255, -1)\n",
        "#     if feather > 0:\n",
        "#         k = feather * 2 + 1\n",
        "#         mask = cv2.GaussianBlur(mask, (k, k), 0)\n",
        "#     return mask\n",
        "\n",
        "# # 5. Processing Loop\n",
        "# frames_generator = sv.get_video_frames_generator(source_path=INPUT_VIDEO_PATH)\n",
        "\n",
        "# with sv.VideoSink(target_path=OUTPUT_VIDEO_PATH, video_info=video_info) as sink:\n",
        "#     frame_idx = -1\n",
        "\n",
        "#     for frame in tqdm(frames_generator, total=video_info.total_frames, desc=\"Master Logic Render\"):\n",
        "#         frame_idx += 1\n",
        "\n",
        "#         enhanced_frame = apply_lighting_fix(frame)\n",
        "#         H, W = enhanced_frame.shape[:2]\n",
        "\n",
        "#         results = model.track(\n",
        "#             enhanced_frame,\n",
        "#             persist=True,\n",
        "#             verbose=False,\n",
        "#             conf=0.03,\n",
        "#             iou=0.4,\n",
        "#             tracker=\"botsort.yaml\"\n",
        "#         )[0]\n",
        "\n",
        "#         detections = sv.Detections.from_ultralytics(results)\n",
        "#         detections = detections[(detections.class_id == 0) | (detections.class_id == 32)]\n",
        "\n",
        "#         # HOOP ROI BOOST\n",
        "#         rx1, ry1, rx2, ry2 = union_gate_roi(HOOP_UPPER_POLYGON, HOOP_LOWER_POLYGON, W, H, pad=30)\n",
        "#         roi = enhanced_frame[ry1:ry2, rx1:rx2]\n",
        "\n",
        "#         roi_ball = None\n",
        "#         if roi.size > 0:\n",
        "#             roi_res = model.predict(roi, verbose=False, conf=0.01, iou=0.35)[0]\n",
        "#             roi_det = sv.Detections.from_ultralytics(roi_res)\n",
        "#             roi_det = roi_det[roi_det.class_id == 32]\n",
        "#             roi_ball = offset_detections(roi_det, dx=rx1, dy=ry1)\n",
        "\n",
        "#         full_ball = detections[detections.class_id == 32]\n",
        "#         merged_ball = concat_dets(full_ball, roi_ball)\n",
        "\n",
        "#         # Ball: predict -> match -> update\n",
        "#         pred_xy = ball_track.predict()\n",
        "#         chosen = pick_best_ball_near_prediction(merged_ball, pred_xy, max_dist=160)\n",
        "\n",
        "#         if chosen is not None and len(chosen) > 0:\n",
        "#             cx, cy, bw, bh = det_centroid_wh(chosen)\n",
        "#             cx = float(cx[0]); cy = float(cy[0])\n",
        "#             bw = float(bw[0]); bh = float(bh[0])\n",
        "\n",
        "#             if not ball_track.initialized:\n",
        "#                 ball_track.init(cx, cy, bw, bh)\n",
        "#             else:\n",
        "#                 ball_track.update(cx, cy, bw, bh)\n",
        "#         else:\n",
        "#             ball_track.mark_missed()\n",
        "\n",
        "#         # Virtual ball from Kalman\n",
        "#         ball_for_zone = None\n",
        "#         ball_cy = None\n",
        "\n",
        "#         if ball_track.initialized and ball_track.missed <= MAX_MISSED_FRAMES:\n",
        "#             bb = ball_track.bbox()\n",
        "#             if bb is not None:\n",
        "#                 ball_xyxy = clamp_xyxy(bb, W, H)\n",
        "#                 ball_cy = float((ball_xyxy[1] + ball_xyxy[3]) / 2.0)\n",
        "#                 ball_for_zone = sv.Detections(\n",
        "#                     xyxy=np.array([ball_xyxy], dtype=np.float32),\n",
        "#                     confidence=np.array([1.0], dtype=np.float32),\n",
        "#                     class_id=np.array([32], dtype=np.int32),\n",
        "#                 )\n",
        "#         else:\n",
        "#             ball_track.initialized = False\n",
        "\n",
        "#         ball_seen = ball_for_zone is not None\n",
        "#         in_upper = upper_zone.trigger(detections=ball_for_zone).any() if ball_seen else False\n",
        "#         in_lower = lower_zone.trigger(detections=ball_for_zone).any() if ball_seen else False\n",
        "\n",
        "#         if in_upper:\n",
        "#             dbg_upper_hits += 1\n",
        "#         if in_lower:\n",
        "#             dbg_lower_hits += 1\n",
        "\n",
        "#         if cooldown > 0:\n",
        "#             cooldown -= 1\n",
        "\n",
        "#         # Attempt state machine\n",
        "#         if attempt[\"phase\"] == \"idle\":\n",
        "#             if ball_seen and in_upper and cooldown == 0:\n",
        "#                 attempt[\"phase\"] = \"saw_upper\"\n",
        "#                 attempt[\"start_frame\"] = frame_idx\n",
        "#                 attempt[\"start_cy\"] = ball_cy\n",
        "\n",
        "#         elif attempt[\"phase\"] == \"saw_upper\":\n",
        "#             if (frame_idx - attempt[\"start_frame\"]) > MAX_TRANSIT_FRAMES:\n",
        "#                 attempt[\"phase\"] = \"idle\"\n",
        "#                 attempt[\"start_frame\"] = None\n",
        "#                 attempt[\"start_cy\"] = None\n",
        "\n",
        "#             elif ball_seen and in_lower and cooldown == 0:\n",
        "#                 down_pixels = ball_cy - float(attempt[\"start_cy\"])\n",
        "#                 if down_pixels >= MIN_DOWN_PIXELS:\n",
        "#                     score += 1\n",
        "#                     cooldown = COOLDOWN_FRAMES\n",
        "#                     dbg_scores += 1\n",
        "\n",
        "#                 attempt[\"phase\"] = \"idle\"\n",
        "#                 attempt[\"start_frame\"] = None\n",
        "#                 attempt[\"start_cy\"] = None\n",
        "\n",
        "#             elif (not ball_seen) and (frame_idx - attempt[\"start_frame\"]) > MISS_RESET_FRAMES:\n",
        "#                 attempt[\"phase\"] = \"idle\"\n",
        "#                 attempt[\"start_frame\"] = None\n",
        "#                 attempt[\"start_cy\"] = None\n",
        "\n",
        "#         # ----------------------------\n",
        "#         # Heatvision base: dark thermal background + heat silhouettes + glow outline\n",
        "#         # ----------------------------\n",
        "#         heat_gray = cv2.cvtColor(enhanced_frame, cv2.COLOR_BGR2GRAY)\n",
        "#         heat_gray = cv2.GaussianBlur(heat_gray, (0, 0), HEAT_BLUR_SIGMA)\n",
        "\n",
        "#         heat_bg = cv2.applyColorMap(heat_gray, HEATVISION_COLORMAP)\n",
        "#         annotated_frame = (heat_bg.astype(np.float32) * BG_DARKEN).clip(0, 255).astype(np.uint8)\n",
        "\n",
        "#         # Persons tracked for continuous trails\n",
        "#         p_xyxy = detections[detections.class_id == 0].xyxy if len(detections) > 0 else np.zeros((0, 4), dtype=np.float32)\n",
        "#         if p_xyxy is None:\n",
        "#             p_xyxy = np.zeros((0, 4), dtype=np.float32)\n",
        "\n",
        "#         person_annot_tracker.update(p_xyxy)\n",
        "#         p_tracked = person_annot_tracker.as_detections()\n",
        "\n",
        "#         # Build silhouette mask for persons + ball\n",
        "#         person_mask = np.zeros((H, W), dtype=np.uint8)\n",
        "#         if p_tracked is not None and len(p_tracked) > 0:\n",
        "#             person_mask = _soft_silhouette_from_xyxy(p_tracked.xyxy, H, W, feather=14)\n",
        "\n",
        "#         ball_mask = np.zeros((H, W), dtype=np.uint8)\n",
        "#         if ball_for_zone is not None and len(ball_for_zone) > 0:\n",
        "#             ball_mask = _soft_silhouette_from_xyxy(ball_for_zone.xyxy, H, W, feather=10)\n",
        "\n",
        "#         sil = cv2.max(person_mask, ball_mask)\n",
        "\n",
        "#         hg = heat_gray.astype(np.float32) / 255.0\n",
        "#         hg = np.power(np.clip(hg, 0.0, 1.0), SUBJECT_GAMMA)\n",
        "#         hg = (hg * 255.0).clip(0, 255).astype(np.uint8)\n",
        "\n",
        "#         heat_subject = cv2.applyColorMap(hg, HEATVISION_COLORMAP)\n",
        "#         heat_subject = (heat_subject.astype(np.float32) * SUBJECT_GAIN).clip(0, 255).astype(np.uint8)\n",
        "\n",
        "#         sil_f = (sil.astype(np.float32) / 255.0)[..., None]\n",
        "#         subj_rgb = (heat_subject.astype(np.float32) * sil_f).clip(0, 255).astype(np.uint8)\n",
        "\n",
        "#         annotated_frame = cv2.add(annotated_frame, subj_rgb)\n",
        "\n",
        "#         if GLOW_DILATE > 0:\n",
        "#             k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (GLOW_DILATE * 2 + 1, GLOW_DILATE * 2 + 1))\n",
        "#             dil = cv2.dilate(sil, k, iterations=1)\n",
        "#             ring = cv2.subtract(dil, sil)\n",
        "#             ring = cv2.GaussianBlur(ring, (0, 0), 3.0)\n",
        "\n",
        "#             ring_f = (ring.astype(np.float32) / 255.0)[..., None]\n",
        "#             glow_rgb = (heat_subject.astype(np.float32) * ring_f * GLOW_ALPHA).clip(0, 255).astype(np.uint8)\n",
        "#             annotated_frame = cv2.add(annotated_frame, glow_rgb)\n",
        "\n",
        "#         # Annotation overlays (kept intact)\n",
        "#         if p_tracked is not None and len(p_tracked) > 0:\n",
        "#             annotated_frame = trace_ann.annotate(scene=annotated_frame, detections=p_tracked)\n",
        "#             annotated_frame = person_ann.annotate(scene=annotated_frame, detections=p_tracked)\n",
        "\n",
        "#         if ball_for_zone is not None:\n",
        "#             annotated_frame = ball_ann.annotate(scene=annotated_frame, detections=ball_for_zone)\n",
        "\n",
        "#         cv2.polylines(annotated_frame, [HOOP_UPPER_POLYGON], True, (0, 255, 255), 2)\n",
        "#         cv2.polylines(annotated_frame, [HOOP_LOWER_POLYGON], True, (255, 255, 0), 2)\n",
        "\n",
        "#         # Scoreboard\n",
        "#         h, w, _ = annotated_frame.shape\n",
        "#         hud_w, margin = 320, 40\n",
        "#         overlay = annotated_frame.copy()\n",
        "#         cv2.rectangle(overlay, (w - hud_w - margin, h - 120), (w - margin, h - 40), (15, 15, 15), -1)\n",
        "#         cv2.rectangle(overlay, (w - hud_w - margin, h - 120), (w - hud_w - margin + 10, h - 40), (0, 255, 0), -1)\n",
        "#         annotated_frame = cv2.addWeighted(overlay, 0.7, annotated_frame, 0.3, 0)\n",
        "\n",
        "#         cv2.putText(annotated_frame, \"BASKETBALL PERFORMANCE\", (w - hud_w - margin + 25, h - 95),\n",
        "#                     cv2.FONT_HERSHEY_SIMPLEX, 0.4, (160, 160, 160), 1, cv2.LINE_AA)\n",
        "#         cv2.putText(annotated_frame, f\"PTS: {score}\", (w - hud_w - margin + 25, h - 55),\n",
        "#                     cv2.FONT_HERSHEY_DUPLEX, 1.2, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "#         sink.write_frame(frame=annotated_frame)\n",
        "\n",
        "# print(f\"\\n✅ Render Complete! AI Counted: {score}.\")\n",
        "# print(\"Debug upper hits:\", dbg_upper_hits, \"lower hits:\", dbg_lower_hits, \"scores:\", dbg_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv_pose_analytics"
      },
      "source": [
        "#### Style C: Projective Pose Analytics\n",
        "\n",
        "The most advanced rendering mode, leveraging `yolo11x-pose.pt` for skeletal data. It includes:\n",
        "- **Kinetic Skeleton Mapping:** Real-time rendering of joint connections based on COCO-17 keypoints.\n",
        "- **Zero-Latency Joints:** Dynamic limb rendering even during high-velocity action.\n",
        "- **Digital Anchor Points:** Abstract ball visualization using central anchor rings on a pitch-black background for pure performance focus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "fe4f4a3c36c24e6b99f37415e5615cba",
            "53f1855f52fb4a1bb0c9066ca119c4fd",
            "b76168e8cd274432a64d1d1db5075e5f",
            "c12484fb63464dd7a72cdae3df6d5706",
            "38503e2809f240b6b64e0f558ac62d41",
            "49a07373ddd64049abf371bd71482c33",
            "565d79ed87474556ab451eb95c81048a",
            "ccb0238a92894b3986fa03e55ccaf0a0",
            "57d3eb67ea564446886d7543af38b5c9",
            "6ee2cae291e54ef9b20f215e62a06d12",
            "6fddc58cf37c4a7eaf2127a0fb9d490e"
          ]
        },
        "id": "dTJ9iDiE8x4y",
        "outputId": "3c33da6e-daa2-4c78-d080-deea45c87fe7"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # AUTO HOOP GATES + ROCK-SOLID BALL (KALMAN + REACQUIRE) + ROBUST SCORE\n",
        "# # (NO tracker_id REQUIRED) + NumPy 1.25 FIX + HOOP ROI BOOST\n",
        "# # FULL SELF-CONTAINED BLOCK (includes annotators + lighting fix)\n",
        "# # ============================================================\n",
        "\n",
        "# # 0. Setup annotators (NO LABELS)\n",
        "# person_ann = sv.RoundBoxAnnotator(thickness=2, color=sv.Color.RED)\n",
        "# ball_ann   = sv.RoundBoxAnnotator(thickness=2, color=sv.Color.WHITE)\n",
        "# trace_ann  = sv.TraceAnnotator(thickness=3, trace_length=50)\n",
        "\n",
        "# # 1. Load Model\n",
        "# model = YOLO(\"yolo11x-seg.pt\")\n",
        "\n",
        "# # 1b. Pose model (for dynamic skeleton rendering only)\n",
        "# pose_model = YOLO(\"yolo11x-pose.pt\")\n",
        "\n",
        "# # ----------------------------\n",
        "# # Lighting fix\n",
        "# # ----------------------------\n",
        "# def apply_lighting_fix(frame):\n",
        "#     lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
        "#     l, a, b = cv2.split(lab)\n",
        "#     clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "#     l2 = clahe.apply(l)\n",
        "#     enhanced = cv2.merge((l2, a, b))\n",
        "#     return cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "# # ----------------------------\n",
        "# # Auto hoop gates from rim color\n",
        "# # ----------------------------\n",
        "# def auto_hoop_gates_from_video(video_path: str):\n",
        "#     cap = cv2.VideoCapture(video_path)\n",
        "#     ok, frame = cap.read()\n",
        "#     cap.release()\n",
        "#     if not ok or frame is None:\n",
        "#         raise RuntimeError(\"Could not read first frame.\")\n",
        "\n",
        "#     H, W = frame.shape[:2]\n",
        "#     hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "#     lower_orange = np.array([5, 60, 60], dtype=np.uint8)\n",
        "#     upper_orange = np.array([30, 255, 255], dtype=np.uint8)\n",
        "#     mask = cv2.inRange(hsv, lower_orange, upper_orange)\n",
        "\n",
        "#     top_h = int(H * 0.30)\n",
        "#     mask[top_h:, :] = 0\n",
        "#     mask[:top_h, :int(W * 0.35)] = 0\n",
        "\n",
        "#     kernel = np.ones((3, 3), np.uint8)\n",
        "#     mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "#     mask = cv2.morphologyEx(mask, cv2.MORPH_DILATE, kernel, iterations=2)\n",
        "\n",
        "#     ys, xs = np.where(mask > 0)\n",
        "#     if len(xs) < 80:\n",
        "#         raise RuntimeError(\"Rim not detected. Widen orange HSV thresholds.\")\n",
        "\n",
        "#     x1, x2 = int(xs.min()), int(xs.max())\n",
        "#     y1, y2 = int(ys.min()), int(ys.max())\n",
        "\n",
        "#     rim_cx = (x1 + x2) / 2.0\n",
        "#     if abs(rim_cx - (W / 2.0)) > (W * 0.22):\n",
        "#         raise RuntimeError(\"Detected orange region is not near hoop center. Adjust mask exclusions.\")\n",
        "\n",
        "#     rim_w = max(1, x2 - x1)\n",
        "#     pad_x = int(max(10, rim_w * 0.20))\n",
        "\n",
        "#     ux1 = max(0, x1 - pad_x)\n",
        "#     ux2 = min(W - 1, x2 + pad_x)\n",
        "\n",
        "#     uy1 = max(0, y1 - 8)\n",
        "#     uy2 = min(H - 1, y2 + 18)\n",
        "\n",
        "#     ly1 = min(H - 1, y2 + 5)\n",
        "#     ly2 = min(H - 1, y2 + 125)\n",
        "\n",
        "#     upper_poly = np.array([[ux1, uy1], [ux2, uy1], [ux2, uy2], [ux1, uy2]], dtype=int)\n",
        "#     lower_poly = np.array([[ux1, ly1], [ux2, ly1], [ux2, ly2], [ux1, ly2]], dtype=int)\n",
        "#     return upper_poly, lower_poly\n",
        "\n",
        "# video_info = sv.VideoInfo.from_video_path(INPUT_VIDEO_PATH)\n",
        "\n",
        "# try:\n",
        "#     HOOP_UPPER_POLYGON, HOOP_LOWER_POLYGON = auto_hoop_gates_from_video(INPUT_VIDEO_PATH)\n",
        "#     print(\"✅ Auto hoop gates detected:\")\n",
        "#     print(\"UPPER:\", HOOP_UPPER_POLYGON.tolist())\n",
        "#     print(\"LOWER:\", HOOP_LOWER_POLYGON.tolist())\n",
        "# except Exception as e:\n",
        "#     print(\"⚠️ Auto hoop gates failed, using fallback. Error:\", str(e))\n",
        "#     HOOP_UPPER_POLYGON = np.array([[140, 0], [330, 0], [330, 95], [140, 95]], dtype=int)\n",
        "#     HOOP_LOWER_POLYGON = np.array([[150, 85], [320, 85], [320, 215], [150, 215]], dtype=int)\n",
        "\n",
        "# upper_zone = sv.PolygonZone(polygon=HOOP_UPPER_POLYGON)\n",
        "# lower_zone = sv.PolygonZone(polygon=HOOP_LOWER_POLYGON)\n",
        "\n",
        "# # ----------------------------\n",
        "# # Ball stabilizer (Kalman filter)\n",
        "# # ----------------------------\n",
        "# class BallTrack:\n",
        "#     def __init__(self):\n",
        "#         self.kf = cv2.KalmanFilter(4, 2)\n",
        "#         self.kf.transitionMatrix = np.array(\n",
        "#             [[1, 0, 1, 0],\n",
        "#              [0, 1, 0, 1],\n",
        "#              [0, 0, 1, 0],\n",
        "#              [0, 0, 0, 1]], dtype=np.float32\n",
        "#         )\n",
        "#         self.kf.measurementMatrix = np.array(\n",
        "#             [[1, 0, 0, 0],\n",
        "#              [0, 1, 0, 0]], dtype=np.float32\n",
        "#         )\n",
        "#         self.kf.processNoiseCov = np.eye(4, dtype=np.float32) * 1e-2\n",
        "#         self.kf.measurementNoiseCov = np.eye(2, dtype=np.float32) * 2.5e-1\n",
        "#         self.kf.errorCovPost = np.eye(4, dtype=np.float32)\n",
        "\n",
        "#         self.initialized = False\n",
        "#         self.missed = 0\n",
        "#         self.w = 24.0\n",
        "#         self.h = 24.0\n",
        "\n",
        "#     def init(self, cx, cy, w, h):\n",
        "#         self.kf.statePost = np.array([[cx], [cy], [0.0], [0.0]], dtype=np.float32)\n",
        "#         self.kf.statePre = self.kf.statePost.copy()\n",
        "#         self.w = float(w)\n",
        "#         self.h = float(h)\n",
        "#         self.initialized = True\n",
        "#         self.missed = 0\n",
        "\n",
        "#     def predict(self):\n",
        "#         if not self.initialized:\n",
        "#             return None\n",
        "#         pred = self.kf.predict()\n",
        "#         return float(pred[0, 0]), float(pred[1, 0])\n",
        "\n",
        "#     def update(self, cx, cy, w=None, h=None):\n",
        "#         m = np.array([[cx], [cy]], dtype=np.float32)\n",
        "#         self.kf.correct(m)\n",
        "#         if w is not None and h is not None:\n",
        "#             self.w = 0.85 * self.w + 0.15 * float(w)\n",
        "#             self.h = 0.85 * self.h + 0.15 * float(h)\n",
        "#         self.missed = 0\n",
        "\n",
        "#     def mark_missed(self):\n",
        "#         if self.initialized:\n",
        "#             self.missed += 1\n",
        "\n",
        "#     def bbox(self):\n",
        "#         if not self.initialized:\n",
        "#             return None\n",
        "#         cx = float(self.kf.statePost[0, 0])\n",
        "#         cy = float(self.kf.statePost[1, 0])\n",
        "#         x1 = cx - self.w / 2.0\n",
        "#         y1 = cy - self.h / 2.0\n",
        "#         x2 = cx + self.w / 2.0\n",
        "#         y2 = cy + self.h / 2.0\n",
        "#         return np.array([x1, y1, x2, y2], dtype=np.float32)\n",
        "\n",
        "# def det_centroid_wh(dets: sv.Detections):\n",
        "#     xyxy = dets.xyxy\n",
        "#     cx = (xyxy[:, 0] + xyxy[:, 2]) / 2.0\n",
        "#     cy = (xyxy[:, 1] + xyxy[:, 3]) / 2.0\n",
        "#     w = (xyxy[:, 2] - xyxy[:, 0])\n",
        "#     h = (xyxy[:, 3] - xyxy[:, 1])\n",
        "#     return cx, cy, w, h\n",
        "\n",
        "# def pick_best_ball_near_prediction(dets_ball: sv.Detections, pred_xy, max_dist=140):\n",
        "#     if dets_ball is None or len(dets_ball) == 0:\n",
        "#         return None\n",
        "\n",
        "#     if pred_xy is None:\n",
        "#         idx = int(np.argmax(dets_ball.confidence)) if dets_ball.confidence is not None else 0\n",
        "#         return dets_ball[[idx]]\n",
        "\n",
        "#     px, py = pred_xy\n",
        "#     cx, cy, _, _ = det_centroid_wh(dets_ball)\n",
        "#     d = np.sqrt((cx - px) ** 2 + (cy - py) ** 2)\n",
        "#     idx = int(np.argmin(d))\n",
        "\n",
        "#     if float(d[idx]) <= max_dist:\n",
        "#         return dets_ball[[idx]]\n",
        "\n",
        "#     idx2 = int(np.argmax(dets_ball.confidence)) if dets_ball.confidence is not None else 0\n",
        "#     return dets_ball[[idx2]]\n",
        "\n",
        "# def clamp_xyxy(xyxy, W, H):\n",
        "#     x1, y1, x2, y2 = map(float, xyxy.tolist())\n",
        "#     x1 = max(0, min(W - 1, x1))\n",
        "#     y1 = max(0, min(H - 1, y1))\n",
        "#     x2 = max(0, min(W - 1, x2))\n",
        "#     y2 = max(0, min(H - 1, y2))\n",
        "#     return np.array([x1, y1, x2, y2], dtype=np.float32)\n",
        "\n",
        "# def union_gate_roi(upper_poly, lower_poly, W, H, pad=20):\n",
        "#     xs = np.concatenate([upper_poly[:, 0], lower_poly[:, 0]])\n",
        "#     ys = np.concatenate([upper_poly[:, 1], lower_poly[:, 1]])\n",
        "#     x1 = max(0, int(xs.min()) - pad)\n",
        "#     y1 = max(0, int(ys.min()) - pad)\n",
        "#     x2 = min(W - 1, int(xs.max()) + pad)\n",
        "#     y2 = min(H - 1, int(ys.max()) + pad)\n",
        "#     return x1, y1, x2, y2\n",
        "\n",
        "# def offset_detections(dets: sv.Detections, dx: int, dy: int):\n",
        "#     if dets is None or len(dets) == 0:\n",
        "#         return dets\n",
        "#     xyxy = dets.xyxy.copy()\n",
        "#     xyxy[:, [0, 2]] += dx\n",
        "#     xyxy[:, [1, 3]] += dy\n",
        "#     return sv.Detections(\n",
        "#         xyxy=xyxy,\n",
        "#         confidence=dets.confidence.copy() if dets.confidence is not None else None,\n",
        "#         class_id=dets.class_id.copy() if dets.class_id is not None else None,\n",
        "#         tracker_id=dets.tracker_id.copy() if dets.tracker_id is not None else None,\n",
        "#     )\n",
        "\n",
        "# def concat_dets(a: sv.Detections, b: sv.Detections):\n",
        "#     if a is None or len(a) == 0:\n",
        "#         return b\n",
        "#     if b is None or len(b) == 0:\n",
        "#         return a\n",
        "#     return sv.Detections(\n",
        "#         xyxy=np.concatenate([a.xyxy, b.xyxy], axis=0),\n",
        "#         confidence=np.concatenate([a.confidence, b.confidence], axis=0)\n",
        "#         if a.confidence is not None and b.confidence is not None else None,\n",
        "#         class_id=np.concatenate([a.class_id, b.class_id], axis=0)\n",
        "#         if a.class_id is not None and b.class_id is not None else None,\n",
        "#         tracker_id=None,\n",
        "#     )\n",
        "\n",
        "# # -----------------------\n",
        "# # Robust scoring state\n",
        "# # -----------------------\n",
        "# score = 0\n",
        "# COOLDOWN_FRAMES = 45\n",
        "# MAX_TRANSIT_FRAMES = 26\n",
        "# MIN_DOWN_PIXELS = 24\n",
        "# MISS_RESET_FRAMES = 20\n",
        "\n",
        "# cooldown = 0\n",
        "# attempt = {\"phase\": \"idle\", \"start_frame\": None, \"start_cy\": None}\n",
        "\n",
        "# ball_track = BallTrack()\n",
        "# MAX_MISSED_FRAMES = 30\n",
        "\n",
        "# dbg_upper_hits = 0\n",
        "# dbg_lower_hits = 0\n",
        "# dbg_scores = 0\n",
        "\n",
        "# # -----------------------\n",
        "# # Continuous person boxes + trail even when Ultralytics tracker ids disappear\n",
        "# # (annotation-only lightweight tracker)\n",
        "# # -----------------------\n",
        "# PERSON_MAX_MISSED = 18\n",
        "# PERSON_MATCH_IOU = 0.18\n",
        "\n",
        "# def _iou_xyxy(a, b):\n",
        "#     ax1, ay1, ax2, ay2 = map(float, a)\n",
        "#     bx1, by1, bx2, by2 = map(float, b)\n",
        "#     ix1 = max(ax1, bx1)\n",
        "#     iy1 = max(ay1, by1)\n",
        "#     ix2 = min(ax2, bx2)\n",
        "#     iy2 = min(ay2, by2)\n",
        "#     iw = max(0.0, ix2 - ix1)\n",
        "#     ih = max(0.0, iy2 - iy1)\n",
        "#     inter = iw * ih\n",
        "#     area_a = max(0.0, (ax2 - ax1)) * max(0.0, (ay2 - ay1))\n",
        "#     area_b = max(0.0, (bx2 - bx1)) * max(0.0, (by2 - by1))\n",
        "#     denom = area_a + area_b - inter\n",
        "#     return (inter / denom) if denom > 1e-6 else 0.0\n",
        "\n",
        "# class _PersonAnnotTracker:\n",
        "#     def __init__(self):\n",
        "#         self.next_id = 1\n",
        "#         self.tracks = {}  # id -> {\"xyxy\": np.array(4), \"missed\": int}\n",
        "\n",
        "#     def update(self, person_xyxy: np.ndarray):\n",
        "#         for tid in list(self.tracks.keys()):\n",
        "#             self.tracks[tid][\"missed\"] += 1\n",
        "\n",
        "#         if person_xyxy is None or len(person_xyxy) == 0:\n",
        "#             for tid in list(self.tracks.keys()):\n",
        "#                 if self.tracks[tid][\"missed\"] > PERSON_MAX_MISSED:\n",
        "#                     self.tracks.pop(tid, None)\n",
        "#             return\n",
        "\n",
        "#         used_det = set()\n",
        "#         track_ids = list(self.tracks.keys())\n",
        "\n",
        "#         for tid in track_ids:\n",
        "#             best_j = -1\n",
        "#             best_iou = 0.0\n",
        "#             tbox = self.tracks[tid][\"xyxy\"]\n",
        "#             for j in range(len(person_xyxy)):\n",
        "#                 if j in used_det:\n",
        "#                     continue\n",
        "#                 iou = _iou_xyxy(tbox, person_xyxy[j])\n",
        "#                 if iou > best_iou:\n",
        "#                     best_iou = iou\n",
        "#                     best_j = j\n",
        "#             if best_j >= 0 and best_iou >= PERSON_MATCH_IOU:\n",
        "#                 self.tracks[tid][\"xyxy\"] = person_xyxy[best_j].astype(np.float32)\n",
        "#                 self.tracks[tid][\"missed\"] = 0\n",
        "#                 used_det.add(best_j)\n",
        "\n",
        "#         for j in range(len(person_xyxy)):\n",
        "#             if j in used_det:\n",
        "#                 continue\n",
        "#             tid = self.next_id\n",
        "#             self.next_id += 1\n",
        "#             self.tracks[tid] = {\"xyxy\": person_xyxy[j].astype(np.float32), \"missed\": 0}\n",
        "\n",
        "#         for tid in list(self.tracks.keys()):\n",
        "#             if self.tracks[tid][\"missed\"] > PERSON_MAX_MISSED:\n",
        "#                 self.tracks.pop(tid, None)\n",
        "\n",
        "#     def as_detections(self):\n",
        "#         if len(self.tracks) == 0:\n",
        "#             return None\n",
        "#         tids = sorted(self.tracks.keys())\n",
        "#         xyxy = np.stack([self.tracks[tid][\"xyxy\"] for tid in tids], axis=0).astype(np.float32)\n",
        "#         return sv.Detections(\n",
        "#             xyxy=xyxy,\n",
        "#             confidence=np.ones((len(tids),), dtype=np.float32),\n",
        "#             class_id=np.zeros((len(tids),), dtype=np.int32),\n",
        "#             tracker_id=np.array(tids, dtype=np.int32),\n",
        "#         )\n",
        "\n",
        "# person_annot_tracker = _PersonAnnotTracker()\n",
        "\n",
        "# # -----------------------\n",
        "# # Skeleton rendering (pose keypoints)\n",
        "# # -----------------------\n",
        "# POSE_CONF = 0.25\n",
        "# KP_CONF = 0.25\n",
        "# SKELETON_THICKNESS = 3\n",
        "# JOINT_RADIUS = 3\n",
        "\n",
        "# # COCO-17 connections (Ultralytics YOLO pose uses COCO keypoints order)\n",
        "# COCO_EDGES = [\n",
        "#     (5, 7), (7, 9),      # left arm\n",
        "#     (6, 8), (8, 10),     # right arm\n",
        "#     (5, 6),              # shoulders\n",
        "#     (5, 11), (6, 12),    # torso\n",
        "#     (11, 12),            # hips\n",
        "#     (11, 13), (13, 15),  # left leg\n",
        "#     (12, 14), (14, 16),  # right leg\n",
        "#     (0, 1), (0, 2),      # nose to eyes\n",
        "#     (1, 3), (2, 4),      # eyes to ears\n",
        "#     (0, 5), (0, 6),      # nose to shoulders\n",
        "# ]\n",
        "\n",
        "# def _draw_pose_skeleton(scene, kpts_xy, kpts_conf, color=(255, 255, 255)):\n",
        "#     # joints\n",
        "#     for i in range(kpts_xy.shape[0]):\n",
        "#         if float(kpts_conf[i]) >= KP_CONF:\n",
        "#             x = int(round(float(kpts_xy[i, 0])))\n",
        "#             y = int(round(float(kpts_xy[i, 1])))\n",
        "#             cv2.circle(scene, (x, y), JOINT_RADIUS, color, -1, cv2.LINE_AA)\n",
        "\n",
        "#     # bones\n",
        "#     for a, b in COCO_EDGES:\n",
        "#         if a >= kpts_xy.shape[0] or b >= kpts_xy.shape[0]:\n",
        "#             continue\n",
        "#         if float(kpts_conf[a]) < KP_CONF or float(kpts_conf[b]) < KP_CONF:\n",
        "#             continue\n",
        "#         x1 = int(round(float(kpts_xy[a, 0])))\n",
        "#         y1 = int(round(float(kpts_xy[a, 1])))\n",
        "#         x2 = int(round(float(kpts_xy[b, 0])))\n",
        "#         y2 = int(round(float(kpts_xy[b, 1])))\n",
        "#         cv2.line(scene, (x1, y1), (x2, y2), color, SKELETON_THICKNESS, cv2.LINE_AA)\n",
        "\n",
        "# def _draw_ball_anchor(scene, xyxy, color=(255, 255, 255), thickness=2):\n",
        "#     x1, y1, x2, y2 = [int(round(v)) for v in xyxy.tolist()]\n",
        "#     if x2 <= x1 or y2 <= y1:\n",
        "#         return\n",
        "#     cx = int((x1 + x2) / 2)\n",
        "#     cy = int((y1 + y2) / 2)\n",
        "#     r = max(3, int(min(x2 - x1, y2 - y1) * 0.35))\n",
        "#     cv2.circle(scene, (cx, cy), r, color, thickness, cv2.LINE_AA)\n",
        "\n",
        "# # 5. Processing Loop\n",
        "# frames_generator = sv.get_video_frames_generator(source_path=INPUT_VIDEO_PATH)\n",
        "\n",
        "# with sv.VideoSink(target_path=OUTPUT_VIDEO_PATH, video_info=video_info) as sink:\n",
        "#     frame_idx = -1\n",
        "\n",
        "#     for frame in tqdm(frames_generator, total=video_info.total_frames, desc=\"Master Logic Render\"):\n",
        "#         frame_idx += 1\n",
        "\n",
        "#         enhanced_frame = apply_lighting_fix(frame)\n",
        "#         H, W = enhanced_frame.shape[:2]\n",
        "\n",
        "#         results = model.track(\n",
        "#             enhanced_frame,\n",
        "#             persist=True,\n",
        "#             verbose=False,\n",
        "#             conf=0.03,\n",
        "#             iou=0.4,\n",
        "#             tracker=\"botsort.yaml\"\n",
        "#         )[0]\n",
        "\n",
        "#         detections = sv.Detections.from_ultralytics(results)\n",
        "#         detections = detections[(detections.class_id == 0) | (detections.class_id == 32)]\n",
        "\n",
        "#         # HOOP ROI BOOST\n",
        "#         rx1, ry1, rx2, ry2 = union_gate_roi(HOOP_UPPER_POLYGON, HOOP_LOWER_POLYGON, W, H, pad=30)\n",
        "#         roi = enhanced_frame[ry1:ry2, rx1:rx2]\n",
        "\n",
        "#         roi_ball = None\n",
        "#         if roi.size > 0:\n",
        "#             roi_res = model.predict(roi, verbose=False, conf=0.01, iou=0.35)[0]\n",
        "#             roi_det = sv.Detections.from_ultralytics(roi_res)\n",
        "#             roi_det = roi_det[roi_det.class_id == 32]\n",
        "#             roi_ball = offset_detections(roi_det, dx=rx1, dy=ry1)\n",
        "\n",
        "#         full_ball = detections[detections.class_id == 32]\n",
        "#         merged_ball = concat_dets(full_ball, roi_ball)\n",
        "\n",
        "#         # Ball: predict -> match -> update\n",
        "#         pred_xy = ball_track.predict()\n",
        "#         chosen = pick_best_ball_near_prediction(merged_ball, pred_xy, max_dist=160)\n",
        "\n",
        "#         if chosen is not None and len(chosen) > 0:\n",
        "#             cx, cy, bw, bh = det_centroid_wh(chosen)\n",
        "#             cx = float(cx[0]); cy = float(cy[0])\n",
        "#             bw = float(bw[0]); bh = float(bh[0])\n",
        "\n",
        "#             if not ball_track.initialized:\n",
        "#                 ball_track.init(cx, cy, bw, bh)\n",
        "#             else:\n",
        "#                 ball_track.update(cx, cy, bw, bh)\n",
        "#         else:\n",
        "#             ball_track.mark_missed()\n",
        "\n",
        "#         # Virtual ball from Kalman\n",
        "#         ball_for_zone = None\n",
        "#         ball_cy = None\n",
        "\n",
        "#         if ball_track.initialized and ball_track.missed <= MAX_MISSED_FRAMES:\n",
        "#             bb = ball_track.bbox()\n",
        "#             if bb is not None:\n",
        "#                 ball_xyxy = clamp_xyxy(bb, W, H)\n",
        "#                 ball_cy = float((ball_xyxy[1] + ball_xyxy[3]) / 2.0)\n",
        "#                 ball_for_zone = sv.Detections(\n",
        "#                     xyxy=np.array([ball_xyxy], dtype=np.float32),\n",
        "#                     confidence=np.array([1.0], dtype=np.float32),\n",
        "#                     class_id=np.array([32], dtype=np.int32),\n",
        "#                 )\n",
        "#         else:\n",
        "#             ball_track.initialized = False\n",
        "\n",
        "#         ball_seen = ball_for_zone is not None\n",
        "#         in_upper = upper_zone.trigger(detections=ball_for_zone).any() if ball_seen else False\n",
        "#         in_lower = lower_zone.trigger(detections=ball_for_zone).any() if ball_seen else False\n",
        "\n",
        "#         if in_upper:\n",
        "#             dbg_upper_hits += 1\n",
        "#         if in_lower:\n",
        "#             dbg_lower_hits += 1\n",
        "\n",
        "#         if cooldown > 0:\n",
        "#             cooldown -= 1\n",
        "\n",
        "#         # Attempt state machine\n",
        "#         if attempt[\"phase\"] == \"idle\":\n",
        "#             if ball_seen and in_upper and cooldown == 0:\n",
        "#                 attempt[\"phase\"] = \"saw_upper\"\n",
        "#                 attempt[\"start_frame\"] = frame_idx\n",
        "#                 attempt[\"start_cy\"] = ball_cy\n",
        "\n",
        "#         elif attempt[\"phase\"] == \"saw_upper\":\n",
        "#             if (frame_idx - attempt[\"start_frame\"]) > MAX_TRANSIT_FRAMES:\n",
        "#                 attempt[\"phase\"] = \"idle\"\n",
        "#                 attempt[\"start_frame\"] = None\n",
        "#                 attempt[\"start_cy\"] = None\n",
        "\n",
        "#             elif ball_seen and in_lower and cooldown == 0:\n",
        "#                 down_pixels = ball_cy - float(attempt[\"start_cy\"])\n",
        "#                 if down_pixels >= MIN_DOWN_PIXELS:\n",
        "#                     score += 1\n",
        "#                     cooldown = COOLDOWN_FRAMES\n",
        "#                     dbg_scores += 1\n",
        "\n",
        "#                 attempt[\"phase\"] = \"idle\"\n",
        "#                 attempt[\"start_frame\"] = None\n",
        "#                 attempt[\"start_cy\"] = None\n",
        "\n",
        "#             elif (not ball_seen) and (frame_idx - attempt[\"start_frame\"]) > MISS_RESET_FRAMES:\n",
        "#                 attempt[\"phase\"] = \"idle\"\n",
        "#                 attempt[\"start_frame\"] = None\n",
        "#                 attempt[\"start_cy\"] = None\n",
        "\n",
        "#         # ----------------------------\n",
        "#         # Output style: black background + real pose skeletons (dynamic limbs)\n",
        "#         # ----------------------------\n",
        "#         annotated_frame = np.zeros((H, W, 3), dtype=np.uint8)\n",
        "\n",
        "#         # Keep your person continuity tracker (for stable trails)\n",
        "#         p_xyxy = detections[detections.class_id == 0].xyxy if len(detections) > 0 else np.zeros((0, 4), dtype=np.float32)\n",
        "#         if p_xyxy is None:\n",
        "#             p_xyxy = np.zeros((0, 4), dtype=np.float32)\n",
        "#         person_annot_tracker.update(p_xyxy)\n",
        "#         p_tracked = person_annot_tracker.as_detections()\n",
        "\n",
        "#         # Pose inference for dynamic joints\n",
        "#         pose_res = pose_model.predict(enhanced_frame, verbose=False, conf=POSE_CONF, iou=0.45)[0]\n",
        "\n",
        "#         # Draw trail using tracked boxes (kept)\n",
        "#         if p_tracked is not None and len(p_tracked) > 0:\n",
        "#             annotated_frame = trace_ann.annotate(scene=annotated_frame, detections=p_tracked)\n",
        "\n",
        "#         # Draw skeletons from pose keypoints\n",
        "#         # Ultralytics pose: pose_res.keypoints.xy -> (N,17,2), pose_res.keypoints.conf -> (N,17)\n",
        "#         if getattr(pose_res, \"keypoints\", None) is not None and pose_res.keypoints is not None:\n",
        "#             kxy = pose_res.keypoints.xy\n",
        "#             kcf = pose_res.keypoints.conf\n",
        "\n",
        "#             if kxy is not None and kcf is not None:\n",
        "#                 for i in range(len(kxy)):\n",
        "#                     _draw_pose_skeleton(annotated_frame, kxy[i], kcf[i], color=(255, 255, 255))\n",
        "\n",
        "#         # Ball anchor\n",
        "#         if ball_for_zone is not None and len(ball_for_zone) > 0:\n",
        "#             _draw_ball_anchor(annotated_frame, ball_for_zone.xyxy[0], color=(255, 255, 255), thickness=2)\n",
        "\n",
        "#         # Hoop gates still shown\n",
        "#         cv2.polylines(annotated_frame, [HOOP_UPPER_POLYGON], True, (0, 255, 255), 2)\n",
        "#         cv2.polylines(annotated_frame, [HOOP_LOWER_POLYGON], True, (255, 255, 0), 2)\n",
        "\n",
        "#         # Scoreboard\n",
        "#         h, w, _ = annotated_frame.shape\n",
        "#         hud_w, margin = 320, 40\n",
        "#         overlay = annotated_frame.copy()\n",
        "#         cv2.rectangle(overlay, (w - hud_w - margin, h - 120), (w - margin, h - 40), (15, 15, 15), -1)\n",
        "#         cv2.rectangle(overlay, (w - hud_w - margin, h - 120), (w - hud_w - margin + 10, h - 40), (0, 255, 0), -1)\n",
        "#         annotated_frame = cv2.addWeighted(overlay, 0.7, annotated_frame, 0.3, 0)\n",
        "\n",
        "#         cv2.putText(annotated_frame, \"BASKETBALL PERFORMANCE\", (w - hud_w - margin + 25, h - 95),\n",
        "#                     cv2.FONT_HERSHEY_SIMPLEX, 0.4, (160, 160, 160), 1, cv2.LINE_AA)\n",
        "#         cv2.putText(annotated_frame, f\"PTS: {score}\", (w - hud_w - margin + 25, h - 55),\n",
        "#                     cv2.FONT_HERSHEY_DUPLEX, 1.2, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "#         sink.write_frame(frame=annotated_frame)\n",
        "\n",
        "# print(f\"\\n✅ Render Complete! AI Counted: {score}.\")\n",
        "# print(\"Debug upper hits:\", dbg_upper_hits, \"lower hits:\", dbg_lower_hits, \"scores:\", dbg_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqnFXIbQDvku"
      },
      "source": [
        "### Step 4: Export Analytics Results\n",
        "\n",
        "Once processing is complete, use this utility to export the final rendered video containing the scoreboards, joint trails, and analytics overlays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "pCW16UGBDzHo",
        "outputId": "228818f0-0dc5-44fb-93d5-ff4a23277b6e"
      },
      "outputs": [],
      "source": [
        "#files.download(OUTPUT_VIDEO_PATH) #download the output video when on colab"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "vision",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "38503e2809f240b6b64e0f558ac62d41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49a07373ddd64049abf371bd71482c33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53f1855f52fb4a1bb0c9066ca119c4fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49a07373ddd64049abf371bd71482c33",
            "placeholder": "​",
            "style": "IPY_MODEL_565d79ed87474556ab451eb95c81048a",
            "value": "Master Logic Render: 100%"
          }
        },
        "565d79ed87474556ab451eb95c81048a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57d3eb67ea564446886d7543af38b5c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ee2cae291e54ef9b20f215e62a06d12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fddc58cf37c4a7eaf2127a0fb9d490e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b76168e8cd274432a64d1d1db5075e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccb0238a92894b3986fa03e55ccaf0a0",
            "max": 1767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57d3eb67ea564446886d7543af38b5c9",
            "value": 1767
          }
        },
        "c12484fb63464dd7a72cdae3df6d5706": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ee2cae291e54ef9b20f215e62a06d12",
            "placeholder": "​",
            "style": "IPY_MODEL_6fddc58cf37c4a7eaf2127a0fb9d490e",
            "value": " 1767/1767 [03:26&lt;00:00,  8.45it/s]"
          }
        },
        "ccb0238a92894b3986fa03e55ccaf0a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe4f4a3c36c24e6b99f37415e5615cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53f1855f52fb4a1bb0c9066ca119c4fd",
              "IPY_MODEL_b76168e8cd274432a64d1d1db5075e5f",
              "IPY_MODEL_c12484fb63464dd7a72cdae3df6d5706"
            ],
            "layout": "IPY_MODEL_38503e2809f240b6b64e0f558ac62d41"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
